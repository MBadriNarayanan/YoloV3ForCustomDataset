{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objects Detection took 1.52460 seconds\n",
      "Object 1: person\n",
      "Object 2: person\n",
      "\n",
      "Total objects been detected: 2\n",
      "Number of objects left after non-maximum suppression: 2\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Start of:\n",
    "Reading input image\n",
    "\"\"\"\n",
    "\n",
    "image_BGR = cv2.imread('images/virat.jpg')\n",
    "\n",
    "\n",
    "cv2.namedWindow('Original Image', cv2.WINDOW_NORMAL)\n",
    "\n",
    "cv2.imshow('Original Image', image_BGR)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyWindow('Original Image')\n",
    "\n",
    "\n",
    "h, w = image_BGR.shape[:2]  # Slicing from tuple only first two elements\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "End of: \n",
    "Reading input image\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Start of:\n",
    "Getting blob from input image\n",
    "\"\"\"\n",
    "\n",
    "# Getting blob from input image\n",
    "# The 'cv2.dnn.blobFromImage' function returns 4-dimensional blob\n",
    "# from input image after mean subtraction, normalizing, and RB channels swapping\n",
    "# Resulted shape has number of images, number of channels, width and height\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(image_BGR, 1 / 255.0, (416, 416),swapRB=True, crop=False)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "End of:\n",
    "Getting blob from input image\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Start of:\n",
    "Loading YOLO v3 network\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "with open('yolo-coco-data/coco.names') as f:\n",
    "    \n",
    "    labels = [line.strip() for line in f]\n",
    "\n",
    "\n",
    "network = cv2.dnn.readNetFromDarknet('yolo-coco-data/yolov3.cfg',\n",
    "                                     'yolo-coco-data/yolov3.weights')\n",
    "\n",
    "layers_names_all = network.getLayerNames()\n",
    "\n",
    "\n",
    "layers_names_output = \\\n",
    "    [layers_names_all[i[0] - 1] for i in network.getUnconnectedOutLayers()]\n",
    "\n",
    "\n",
    "probability_minimum = 0.5\n",
    "\n",
    "\n",
    "threshold = 0.3\n",
    "\n",
    "colours = np.random.randint(0, 255, size=(len(labels), 3), dtype='uint8')\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "End of:\n",
    "Loading YOLO v3 network\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Start of:\n",
    "Implementing Forward pass\n",
    "\"\"\"\n",
    "\n",
    "# Implementing forward pass with our blob and only through output layers\n",
    "# Calculating at the same time, needed time for forward pass\n",
    "\n",
    "network.setInput(blob)  # setting blob as input to the network\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "output_from_network = network.forward(layers_names_output)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print('Objects Detection took {:.5f} seconds'.format(end - start))\n",
    "\n",
    "\"\"\"\n",
    "End of:\n",
    "Implementing Forward pass\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Start of:\n",
    "Getting bounding boxes\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "bounding_boxes = []\n",
    "confidences = []\n",
    "class_numbers = []\n",
    "\n",
    "\n",
    "# Going through all output layers after feed forward pass\n",
    "for result in output_from_network:\n",
    "    \n",
    "    # Going through all detections from current output layer\n",
    "    for detected_objects in result:\n",
    "        \n",
    "        # Getting 80 classes' probabilities for current detected object\n",
    "        scores = detected_objects[5 :]\n",
    "        \n",
    "        # Getting index of the class with the maximum value of probability\n",
    "        \n",
    "        class_current = np.argmax(scores)\n",
    "        \n",
    "        # Getting value of probability for defined class\n",
    "        \n",
    "        confidence_current = scores[class_current]\n",
    "\n",
    "        # # Check point\n",
    "        # # Every 'detected_objects' numpy array has first 4 numbers with\n",
    "        # # bounding box coordinates and rest 80 with probabilities for every class\n",
    "        # print(detected_objects.shape)  # (85,)\n",
    "\n",
    "        # Eliminating weak predictions with minimum probability\n",
    "        \n",
    "        if confidence_current > probability_minimum:\n",
    "            \n",
    "            # Scaling bounding box coordinates to the initial image size\n",
    "            # YOLO data format keeps coordinates for center of bounding box\n",
    "            # and its current width and height\n",
    "            # That is why we can just multiply them elementwise\n",
    "            # to the width and height\n",
    "            # of the original image and in this way get coordinates for center\n",
    "            # of bounding box, its width and height for original image\n",
    "            \n",
    "            box_current = detected_objects[0:4] * np.array([w, h, w, h])\n",
    "\n",
    "            # Now, from YOLO data format, we can get top left corner coordinates\n",
    "            # that are x_min and y_min\n",
    "            x_center, y_center, box_width, box_height = box_current\n",
    "            \n",
    "            x_min = int(x_center - (box_width / 2))\n",
    "            \n",
    "            y_min = int(y_center - (box_height / 2))\n",
    "\n",
    "            # Adding results into prepared lists\n",
    "            \n",
    "            bounding_boxes.append([x_min, y_min, int(box_width), int(box_height)])\n",
    "            \n",
    "            confidences.append(float(confidence_current))\n",
    "            \n",
    "            class_numbers.append(class_current)\n",
    "\n",
    "\"\"\"\n",
    "End of:\n",
    "Getting bounding boxes\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Start of:\n",
    "Non-maximum suppression\n",
    "\"\"\"\n",
    "\n",
    "results = cv2.dnn.NMSBoxes(bounding_boxes, confidences,probability_minimum, threshold)\n",
    "\n",
    "\"\"\"\n",
    "End of:\n",
    "Non-maximum suppression\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Start of:\n",
    "Drawing bounding boxes and labels\n",
    "\"\"\"\n",
    "\n",
    "# Defining counter for detected objects\n",
    "\n",
    "counter = 1\n",
    "\n",
    "# Checking if there is at least one detected object after non-maximum suppression\n",
    "\n",
    "if len(results) > 0 :\n",
    "    \n",
    "    # Going through indexes of results\n",
    "    for i in results.flatten():\n",
    "        # Showing labels of the detected objects\n",
    "        print('Object {0}: {1}'.format(counter, labels[int(class_numbers[i])]))\n",
    "\n",
    "        # Incrementing counter\n",
    "        counter += 1\n",
    "\n",
    "        # Getting current bounding box coordinates,\n",
    "        # its width and height\n",
    "        \n",
    "        x_min, y_min = bounding_boxes[i][0], bounding_boxes[i][1]\n",
    "        box_width, box_height = bounding_boxes[i][2], bounding_boxes[i][3]\n",
    "\n",
    "        # Preparing colour for current bounding box\n",
    "        # and converting from numpy array to list\n",
    "        \n",
    "        colour_box_current = colours[class_numbers[i]].tolist()\n",
    "\n",
    "        # Drawing bounding box on the original image\n",
    "        cv2.rectangle(image_BGR, (x_min, y_min),\n",
    "                      (x_min + box_width, y_min + box_height),\n",
    "                      colour_box_current, 2)\n",
    "\n",
    "        # Preparing text with label and confidence for current bounding box\n",
    "        text_box_current = '{}: {:.4f}'.format(labels[int(class_numbers[i])],\n",
    "                                               confidences[i])\n",
    "\n",
    "        # Putting text with label and confidence on the original image\n",
    "        cv2.putText(image_BGR, text_box_current, (x_min, y_min - 5),\n",
    "                    cv2.FONT_HERSHEY_COMPLEX, 0.7, colour_box_current, 2)\n",
    "\n",
    "print()\n",
    "print('Total objects been detected:', len(bounding_boxes))\n",
    "print('Number of objects left after non-maximum suppression:', counter - 1)\n",
    "\n",
    "\"\"\"\n",
    "End of:\n",
    "Drawing bounding boxes and labels\n",
    "\"\"\"\n",
    "\n",
    "cv2.namedWindow('Detections', cv2.WINDOW_NORMAL)\n",
    "\n",
    "cv2.imshow('Detections', image_BGR)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyWindow('Detections')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
